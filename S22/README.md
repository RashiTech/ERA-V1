# The School of AI - GPT model (pythia-160m) with 0.16 Billion parameters trained from Scratch with RedPajama-1T-sample on V100 GPU

### ERAv1 partner Madhur Prakash Garg

## Hugging face app hosted : https://huggingface.co/spaces/RashiAgarwal/TSAIGPTRedPajama

## Training logs
### Loss of 3.5 achieved in 32,000 iterations

![image](https://github.com/RashiTech/ERA-V1/assets/90626052/035bf320-b91a-4206-a56a-ff1bbc672e82)

## Predictions



