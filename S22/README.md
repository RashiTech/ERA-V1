# The School of AI - GPT model (pythia-160m) with 0.16 Billion parameters trained from Scratch with RedPajama-1T-sample on V100 GPU

### ERAv1 partner Madhur Prakash Garg

## Hugging face app hosted : https://huggingface.co/spaces/RashiAgarwal/TSAIGPTRedPajama

## Training logs
### Loss of 3.5 achieved in 32,000 iterations

![image](https://github.com/RashiTech/ERA-V1/assets/90626052/035bf320-b91a-4206-a56a-ff1bbc672e82)

## Predictions

![image](https://github.com/RashiTech/ERA-V1/assets/90626052/20b2250c-76e4-490e-a537-ac78261c70f5)

![image](https://github.com/RashiTech/ERA-V1/assets/90626052/3b1dd45f-be38-4e34-990a-1e85c4c85fc3)

![image](https://github.com/RashiTech/ERA-V1/assets/90626052/88726c2b-0bf0-4b31-af56-4f019c1f5e75)

![image](https://github.com/RashiTech/ERA-V1/assets/90626052/b058426b-d592-46d0-b8a1-95065091c240)

