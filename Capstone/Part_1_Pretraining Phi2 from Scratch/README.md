# Capstone- The School of AI - ERA v1

## Part 1- Pretraining of Language Model Microsoft/Phi-2

### Project Details

####1. Large Language Model Microsoft-phi-2 (2.7 Billion Parameters) pre-trained from scratch.

####2. Model trained on a cleaned 100MB data (zipped) - A small subset of RedPajama dataset- only cc and c4

<img width="630" alt="image" src="https://github.com/RashiTech/ERA-V1/assets/90626052/038450e0-7447-41a0-9c3d-c4249830deb9">


####1. Large Language Model Microsoft-phi-2 pre-trained from scratch

####1. Large Language Model Microsoft-phi-2 pre-trained from scratch
